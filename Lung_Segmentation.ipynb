{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Improved Lung Segmentation using Residual U-Net\n",
                "\n",
                "This notebook implements a Residual U-Net for lung segmentation from CT images. It includes:\n",
                "- **Residual U-Net Architecture**\n",
                "- **Dice + BCE Loss Function**\n",
                "- **Albumentations Data Augmentation**\n",
                "- **Training Visualization (Loss & IoU Curves)**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import random\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import transforms\n",
                "import torchvision\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "from PIL import Image\n",
                "from tqdm import tqdm\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import Tuple, List, Optional, Dict, Any"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Configuration ---\n",
                "class Config:\n",
                "    \"\"\"Configuration for the Lung Segmentation training pipeline.\"\"\"\n",
                "    SEED = 42\n",
                "    IMAGE_HEIGHT = 256\n",
                "    IMAGE_WIDTH = 256\n",
                "    BATCH_SIZE = 8\n",
                "    LEARNING_RATE = 1e-4\n",
                "    NUM_EPOCHS = 20\n",
                "    NUM_WORKERS = 0  # Set to 0 to avoid DataLoader crashes on Mac/Windows\n",
                "    PIN_MEMORY = True\n",
                "    LOAD_MODEL = False\n",
                "    TRAIN_IMG_DIR = \"Train/Images/\"\n",
                "    TRAIN_MASK_DIR = \"Train/Masks/\"\n",
                "    VAL_IMG_DIR = \"Test/Images/\"\n",
                "    VAL_MASK_DIR = \"Test/Masks/\"\n",
                "    # Check for MPS (Mac), CUDA, or CPU\n",
                "    DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "\n",
                "def seed_everything(seed: int = 42):\n",
                "    \"\"\"Sets the seed for reproducibility.\"\"\"\n",
                "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed(seed)\n",
                "    torch.cuda.manual_seed_all(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "    torch.backends.cudnn.benchmark = False\n",
                "\n",
                "seed_everything(Config.SEED)\n",
                "print(f\"Using device: {Config.DEVICE}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Dataset ---\n",
                "class LungDataset(Dataset):\n",
                "    \"\"\"\n",
                "    Custom Dataset for Lung Segmentation.\n",
                "    Expects images and masks in separate directories.\n",
                "    \"\"\"\n",
                "    def __init__(self, image_dir: str, mask_dir: str, transform: Optional[A.Compose] = None):\n",
                "        self.image_dir = image_dir\n",
                "        self.mask_dir = mask_dir\n",
                "        self.transform = transform\n",
                "        self.images = os.listdir(image_dir) if os.path.exists(image_dir) else []\n",
                "\n",
                "    def __len__(self) -> int:\n",
                "        return len(self.images)\n",
                "\n",
                "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
                "        img_path = os.path.join(self.image_dir, self.images[index])\n",
                "        mask_path = os.path.join(self.mask_dir, self.images[index]) # Assuming same filename\n",
                "\n",
                "        # Load image and mask\n",
                "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
                "        mask = np.array(Image.open(mask_path).convert(\"L\"), dtype=np.float32)\n",
                "        \n",
                "        # Preprocess mask: 0.0 or 1.0\n",
                "        mask[mask == 255.0] = 1.0\n",
                "        \n",
                "        if self.transform is not None:\n",
                "            augmentations = self.transform(image=image, mask=mask)\n",
                "            image = augmentations[\"image\"]\n",
                "            mask = augmentations[\"mask\"]\n",
                "\n",
                "        return image, mask"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Data Augmentation ---\n",
                "def get_train_transforms(height: int, width: int) -> A.Compose:\n",
                "    \"\"\"Returns the training data augmentation pipeline.\"\"\"\n",
                "    return A.Compose(\n",
                "        [\n",
                "            A.Resize(height=height, width=width),\n",
                "            A.Rotate(limit=35, p=1.0),\n",
                "            A.HorizontalFlip(p=0.5),\n",
                "            A.VerticalFlip(p=0.1),\n",
                "            A.Normalize(\n",
                "                mean=[0.0, 0.0, 0.0],\n",
                "                std=[1.0, 1.0, 1.0],\n",
                "                max_pixel_value=255.0,\n",
                "            ),\n",
                "            ToTensorV2(),\n",
                "        ],\n",
                "    )\n",
                "\n",
                "def get_val_transforms(height: int, width: int) -> A.Compose:\n",
                "    \"\"\"Returns the validation data augmentation pipeline (resize & normalize only).\"\"\"\n",
                "    return A.Compose(\n",
                "        [\n",
                "            A.Resize(height=height, width=width),\n",
                "            A.Normalize(\n",
                "                mean=[0.0, 0.0, 0.0],\n",
                "                std=[1.0, 1.0, 1.0],\n",
                "                max_pixel_value=255.0,\n",
                "            ),\n",
                "            ToTensorV2(),\n",
                "        ],\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Model: Residual U-Net ---\n",
                "class ResidualBlock(nn.Module):\n",
                "    \"\"\"Residual Block with two convolution layers.\"\"\"\n",
                "    def __init__(self, in_channels: int, out_channels: int, stride: int = 1):\n",
                "        super().__init__()\n",
                "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
                "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
                "        self.relu = nn.ReLU(inplace=True)\n",
                "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
                "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
                "        \n",
                "        self.shortcut = nn.Sequential()\n",
                "        if stride != 1 or in_channels != out_channels:\n",
                "            self.shortcut = nn.Sequential(\n",
                "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
                "                nn.BatchNorm2d(out_channels)\n",
                "            )\n",
                "\n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        out = self.relu(self.bn1(self.conv1(x)))\n",
                "        out = self.bn2(self.conv2(out))\n",
                "        out += self.shortcut(x)\n",
                "        out = self.relu(out)\n",
                "        return out\n",
                "\n",
                "class ResUNet(nn.Module):\n",
                "    \"\"\"\n",
                "    Residual U-Net Architecture.\n",
                "    Combines the strengths of U-Net (skip connections) and ResNet (residual learning).\n",
                "    \"\"\"\n",
                "    def __init__(self, in_channels: int = 3, out_channels: int = 1, features: List[int] = [64, 128, 256, 512]):\n",
                "        super().__init__()\n",
                "        self.ups = nn.ModuleList()\n",
                "        self.downs = nn.ModuleList()\n",
                "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
                "\n",
                "        # Encoder (Downsampling)\n",
                "        for feature in features:\n",
                "            self.downs.append(ResidualBlock(in_channels, feature))\n",
                "            in_channels = feature\n",
                "\n",
                "        # Decoder (Upsampling)\n",
                "        for feature in reversed(features):\n",
                "            self.ups.append(\n",
                "                nn.ConvTranspose2d(\n",
                "                    feature * 2, feature, kernel_size=2, stride=2\n",
                "                )\n",
                "            )\n",
                "            self.ups.append(ResidualBlock(feature * 2, feature))\n",
                "\n",
                "        self.bottleneck = ResidualBlock(features[-1], features[-1] * 2)\n",
                "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
                "\n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        skip_connections = []\n",
                "\n",
                "        for down in self.downs:\n",
                "            x = down(x)\n",
                "            skip_connections.append(x)\n",
                "            x = self.pool(x)\n",
                "\n",
                "        x = self.bottleneck(x)\n",
                "        skip_connections = skip_connections[::-1]\n",
                "\n",
                "        for idx in range(0, len(self.ups), 2):\n",
                "            x = self.ups[idx](x)\n",
                "            skip_connection = skip_connections[idx // 2]\n",
                "\n",
                "            if x.shape != skip_connection.shape:\n",
                "                x = transforms.functional.resize(x, size=skip_connection.shape[2:])\n",
                "\n",
                "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
                "            x = self.ups[idx + 1](concat_skip)\n",
                "\n",
                "        return self.final_conv(x)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Loss Function ---\n",
                "class DiceBCELoss(nn.Module):\n",
                "    \"\"\"\n",
                "    Combination of Binary Cross Entropy Loss and Dice Loss.\n",
                "    Helps with class imbalance and improves segmentation quality (IoU).\n",
                "    \"\"\"\n",
                "    def __init__(self, weight=None, size_average=True):\n",
                "        super(DiceBCELoss, self).__init__()\n",
                "\n",
                "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor, smooth: float = 1.0) -> torch.Tensor:\n",
                "        # Flatten inputs and targets\n",
                "        inputs = torch.sigmoid(inputs)\n",
                "        inputs = inputs.view(-1)\n",
                "        targets = targets.view(-1)\n",
                "        \n",
                "        # Dice Loss\n",
                "        intersection = (inputs * targets).sum()\n",
                "        dice_loss = 1 - (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
                "        \n",
                "        # BCE Loss\n",
                "        bce_loss = nn.BCELoss()(inputs, targets)\n",
                "        \n",
                "        return bce_loss + dice_loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Metrics ---\n",
                "def calculate_iou(pred_mask: torch.Tensor, true_mask: torch.Tensor, threshold: float = 0.5) -> float:\n",
                "    \"\"\"Calculates Intersection over Union (IoU) score.\"\"\"\n",
                "    pred_mask = (torch.sigmoid(pred_mask) > threshold).float()\n",
                "    \n",
                "    intersection = (pred_mask * true_mask).sum()\n",
                "    union = pred_mask.sum() + true_mask.sum() - intersection\n",
                "    \n",
                "    if union == 0:\n",
                "        return 1.0\n",
                "    \n",
                "    return (intersection / union).item()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Training Loop ---\n",
                "def train_fn(loader: DataLoader, model: nn.Module, optimizer: optim.Optimizer, loss_fn: nn.Module, scaler: torch.cuda.amp.GradScaler):\n",
                "    \"\"\"Training function for one epoch.\"\"\"\n",
                "    model.train()\n",
                "    loop = tqdm(loader, desc=\"Training\")\n",
                "    epoch_loss = 0\n",
                "    epoch_iou = 0\n",
                "\n",
                "    for batch_idx, (data, targets) in enumerate(loop):\n",
                "        data = data.to(Config.DEVICE)\n",
                "        targets = targets.float().unsqueeze(1).to(Config.DEVICE)\n",
                "\n",
                "        # Forward\n",
                "        if Config.DEVICE == \"cuda\":\n",
                "            with torch.cuda.amp.autocast():\n",
                "                predictions = model(data)\n",
                "                loss = loss_fn(predictions, targets)\n",
                "        else:\n",
                "            predictions = model(data)\n",
                "            loss = loss_fn(predictions, targets)\n",
                "\n",
                "        # Backward\n",
                "        optimizer.zero_grad()\n",
                "        if Config.DEVICE == \"cuda\":\n",
                "            scaler.scale(loss).backward()\n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "        else:\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "\n",
                "        # Metrics\n",
                "        iou = calculate_iou(predictions, targets)\n",
                "        epoch_loss += loss.item()\n",
                "        epoch_iou += iou\n",
                "\n",
                "        # Update tqdm loop\n",
                "        loop.set_postfix(loss=loss.item(), iou=iou)\n",
                "    \n",
                "    return epoch_loss / len(loader), epoch_iou / len(loader)\n",
                "\n",
                "def check_accuracy(loader: DataLoader, model: nn.Module, device: str = \"cuda\"):\n",
                "    \"\"\"Evaluates the model on validation set.\"\"\"\n",
                "    model.eval()\n",
                "    num_correct = 0\n",
                "    num_pixels = 0\n",
                "    dice_score = 0\n",
                "    iou_score = 0\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for x, y in loader:\n",
                "            x = x.to(device)\n",
                "            y = y.to(device).unsqueeze(1)\n",
                "            preds = torch.sigmoid(model(x))\n",
                "            preds = (preds > 0.5).float()\n",
                "            \n",
                "            num_correct += (preds == y).sum()\n",
                "            num_pixels += torch.numel(preds)\n",
                "            \n",
                "            # Dice Score\n",
                "            dice_score += (2 * (preds * y).sum()) / (\n",
                "                (preds + y).sum() + 1e-8\n",
                "            )\n",
                "            \n",
                "            # IoU Score\n",
                "            intersection = (preds * y).sum()\n",
                "            union = preds.sum() + y.sum() - intersection\n",
                "            iou_score += (intersection + 1e-8) / (union + 1e-8)\n",
                "\n",
                "    print(f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\")\n",
                "    print(f\"Dice score: {dice_score/len(loader)}\")\n",
                "    print(f\"IoU score: {iou_score/len(loader)}\")\n",
                "    \n",
                "    return iou_score/len(loader)\n",
                "\n",
                "def save_predictions_as_imgs(loader: DataLoader, model: nn.Module, folder: str = \"saved_images/\", device: str = \"cuda\"):\n",
                "    \"\"\"Saves predicted masks as images.\"\"\"\n",
                "    os.makedirs(folder, exist_ok=True)\n",
                "    model.eval()\n",
                "    for idx, (x, y) in enumerate(loader):\n",
                "        x = x.to(device=device)\n",
                "        with torch.no_grad():\n",
                "            preds = torch.sigmoid(model(x))\n",
                "            preds = (preds > 0.5).float()\n",
                "        \n",
                "        # Save only first batch to avoid clutter\n",
                "        if idx == 0:\n",
                "            for i in range(x.shape[0]):\n",
                "                torchvision.utils.save_image(preds[i], f\"{folder}/pred_{i}.png\")\n",
                "                torchvision.utils.save_image(y[i].unsqueeze(0), f\"{folder}/true_{i}.png\")\n",
                "            break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Main Execution ---\n",
                "\n",
                "# Initialize model, loss, optimizer\n",
                "model = ResUNet(in_channels=3, out_channels=1).to(Config.DEVICE)\n",
                "loss_fn = DiceBCELoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=Config.LEARNING_RATE)\n",
                "scaler = torch.cuda.amp.GradScaler()\n",
                "\n",
                "# Data Loaders\n",
                "train_ds = LungDataset(\n",
                "    image_dir=Config.TRAIN_IMG_DIR,\n",
                "    mask_dir=Config.TRAIN_MASK_DIR,\n",
                "    transform=get_train_transforms(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH),\n",
                ")\n",
                "\n",
                "val_ds = LungDataset(\n",
                "    image_dir=Config.VAL_IMG_DIR,\n",
                "    mask_dir=Config.VAL_MASK_DIR,\n",
                "    transform=get_val_transforms(Config.IMAGE_HEIGHT, Config.IMAGE_WIDTH),\n",
                ")\n",
                "\n",
                "train_loader = DataLoader(\n",
                "    train_ds,\n",
                "    batch_size=Config.BATCH_SIZE,\n",
                "    num_workers=Config.NUM_WORKERS,\n",
                "    pin_memory=Config.PIN_MEMORY,\n",
                "    shuffle=True,\n",
                ")\n",
                "\n",
                "val_loader = DataLoader(\n",
                "    val_ds,\n",
                "    batch_size=Config.BATCH_SIZE,\n",
                "    num_workers=Config.NUM_WORKERS,\n",
                "    pin_memory=Config.PIN_MEMORY,\n",
                "    shuffle=False,\n",
                ")\n",
                "\n",
                "# Training Loop with History Tracking\n",
                "history = {'train_loss': [], 'train_iou': [], 'val_iou': []}\n",
                "best_iou = 0.0\n",
                "\n",
                "for epoch in range(Config.NUM_EPOCHS):\n",
                "    print(f\"Epoch [{epoch+1}/{Config.NUM_EPOCHS}]\")\n",
                "    loss, iou = train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
                "    \n",
                "    # Check accuracy\n",
                "    val_iou = check_accuracy(val_loader, model, device=Config.DEVICE)\n",
                "    \n",
                "    # Store history\n",
                "    history['train_loss'].append(loss)\n",
                "    history['train_iou'].append(iou)\n",
                "    history['val_iou'].append(val_iou)\n",
                "    \n",
                "    if val_iou > best_iou:\n",
                "        best_iou = val_iou\n",
                "        torch.save(model.state_dict(), \"best_resunet_model.pth\")\n",
                "        print(\"Model saved!\")\n",
                "        \n",
                "    # Optional: Save predictions every epoch or at the end\n",
                "    # save_predictions_as_imgs(val_loader, model, folder=\"saved_images/\", device=Config.DEVICE)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Visualization ---\n",
                "plt.figure(figsize=(15, 5))\n",
                "\n",
                "# Plot Loss\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(range(1, Config.NUM_EPOCHS + 1), history['train_loss'], label='Train Loss', marker='o')\n",
                "plt.title('Training Loss per Epoch')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('Loss')\n",
                "plt.grid(True)\n",
                "plt.legend()\n",
                "\n",
                "# Plot IoU\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(range(1, Config.NUM_EPOCHS + 1), history['train_iou'], label='Train IoU', marker='o')\n",
                "plt.plot(range(1, Config.NUM_EPOCHS + 1), history['val_iou'], label='Val IoU', marker='s')\n",
                "plt.title('IoU Score per Epoch')\n",
                "plt.xlabel('Epoch')\n",
                "plt.ylabel('IoU')\n",
                "plt.grid(True)\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}